<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,统计学习方法," />










<meta name="description" content="《机器学习》的第四章与《统计学习方法》的第五章都是在介绍决策树方法，因此写在一起。 决策树决策树（decision tree）是一种基本的分类与回归方法，一般将其用于分类的较多。决策树模型称树形结构，在分类问题中，表示基于特征对实例进行分类的过程。也可以看做是一种定义在特征空间与类空间上的条件概率分布。">
<meta name="keywords" content="机器学习,统计学习方法">
<meta property="og:type" content="article">
<meta property="og:title" content="《统计学习方法》第五章笔记">
<meta property="og:url" content="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/index.html">
<meta property="og:site_name" content="neutronar">
<meta property="og:description" content="《机器学习》的第四章与《统计学习方法》的第五章都是在介绍决策树方法，因此写在一起。 决策树决策树（decision tree）是一种基本的分类与回归方法，一般将其用于分类的较多。决策树模型称树形结构，在分类问题中，表示基于特征对实例进行分类的过程。也可以看做是一种定义在特征空间与类空间上的条件概率分布。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/决策树示意图.jpg">
<meta property="og:image" content="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/决策树生成.jpg">
<meta property="og:image" content="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/预剪枝.jpg">
<meta property="og:updated_time" content="2018-05-22T02:34:39.375Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《统计学习方法》第五章笔记">
<meta name="twitter:description" content="《机器学习》的第四章与《统计学习方法》的第五章都是在介绍决策树方法，因此写在一起。 决策树决策树（decision tree）是一种基本的分类与回归方法，一般将其用于分类的较多。决策树模型称树形结构，在分类问题中，表示基于特征对实例进行分类的过程。也可以看做是一种定义在特征空间与类空间上的条件概率分布。">
<meta name="twitter:image" content="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/决策树示意图.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/"/>





  <title>《统计学习方法》第五章笔记 | neutronar</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">neutronar</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一个普通学生的学习笔记</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/24/统计学习方法第五章笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neutronar">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/mountain.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neutronar">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">《统计学习方法》第五章笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-24T00:00:00+08:00">
                2018-03-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>《机器学习》的第四章与《统计学习方法》的第五章都是在介绍决策树方法，因此写在一起。</p>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树（decision tree）是一种基本的分类与回归方法，一般将其用于分类的较多。决策树模型称树形结构，在分类问题中，表示基于特征对实例进行分类的过程。也可以看做是一种定义在特征空间与类空间上的条件概率分布。<br><a id="more"></a></p>
<h2 id="决策树模型："><a href="#决策树模型：" class="headerlink" title="决策树模型："></a>决策树模型：</h2><p>分类决策树是一种描述对实例进行分类的树形结构，决策树由结点（node）和有向边（directed edge）组成。其中结点分为内部结点（internal node）和叶结点（leaf node），如图为一个对西瓜进行分类的决策树示意图：<br><img src="/2018/03/24/统计学习方法第五章笔记/./决策树示意图.jpg" alt="Alt text"><br>决策树的路径具有一个重要性质：互斥且完备。这就是说，每一个实例都被一条且只有一条路径或规则所覆盖。（对于任一实例，都只能找到通往唯一叶节点的唯一路径）。</p>
<h2 id="决策树学习："><a href="#决策树学习：" class="headerlink" title="决策树学习："></a>决策树学习：</h2><p>决策树学习本质上是从训练数据集中归纳出一组分类规则。方法是递归地选择特征，并根据该特征对训练数据进行分割，直至所有的数据都被归类。可以想见，特征选择的顺序不同，分割点不同，将得到多个适应训练数据的决策树。</p>
<h3 id="①如何把最优的决策树找出来呢？"><a href="#①如何把最优的决策树找出来呢？" class="headerlink" title="①如何把最优的决策树找出来呢？"></a>①如何把最优的决策树找出来呢？</h3><p>直观上有一种策略：每次选择特征的时候，都选择当前条件下的，能够最有效地划分数据集的最优特征。<br>显然，这种策略是启发式的，可以看做是一种“贪心算法”，其找到的解并不一定是全局最优解，但一般可以作为一个次最优解，在实际应用中已经足够了。</p>
<h3 id="②什么样的特征是最优特征呢？如何定义划分的“有效”程度？"><a href="#②什么样的特征是最优特征呢？如何定义划分的“有效”程度？" class="headerlink" title="②什么样的特征是最优特征呢？如何定义划分的“有效”程度？"></a>②什么样的特征是最优特征呢？如何定义划分的“有效”程度？</h3><p>通常特征选择的准则是信息增益（ID3算法）或信息增益比（C4.5算法）或基尼指数（CART分类算法）。</p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>学习特征选择的准则前，需要了解熵的定义。随机变量X的熵定义为：</p>
<script type="math/tex; mode=display">H(X) = -\sum_{i=1}^{n}p_i log(p_i)</script><p>高中物理我们就接触了熵的概念，系统的熵值越大表示系统的不确定程度越大。<strong>当我们得知了关于系统的某个信息，并依此对系统进行操作（排序，分割等等），系统的不确定性就会降低。</strong>对一个数据集来说也是这样，每选择一个特征将其划分一次，都会降低数据集的不确定程度，于是在每一次划分时，都选择那个能让系统的熵降低得最多的特征，即为最优特征。</p>
<p>信息增益、信息增益比、基尼指数都是在这个思想下构建的用来表示划分有效性的一个标准。</p>
<h3 id="信息增益："><a href="#信息增益：" class="headerlink" title="信息增益："></a>信息增益：</h3><blockquote>
<p><strong>定义5.2（信息增益）</strong> 特征$A$对训练数据集$D$的信息增益$g(D,A)$，定义为集合$D$的经验熵$H(D)$与特征$A$给定条件下$D$的经验条件熵$H(D\mid A)$之差，即</p>
<script type="math/tex; mode=display">g(D,A)=H(D)-H(D\mid A)</script></blockquote>
<p>信息增益越大，说明用特征$A$对数据集的划分降低了越多的熵值。需要注意，上式中条件熵与特征可取值的数目成正相关，因此该准则偏向选择取值多的特征作为最优特征。</p>
<p>注：熵$H(Y)$与条件熵$H(Y|X)$之差称为互信息（mutual information）。可见，决策树学习中的信息增益等价于训练数据集中类与特征的互信息。关于更多互信息的介绍，可以见此博客：<a href="https://blog.csdn.net/haolexiao/article/details/70142571" target="_blank" rel="noopener">《信息量，信息熵，交叉熵，KL散度和互信息（信息增益）》</a></p>
<h3 id="信息增益比："><a href="#信息增益比：" class="headerlink" title="信息增益比："></a>信息增益比：</h3><blockquote>
<p><strong>定义5.3（信息增益比）</strong>  特征$A$对训练数据集$D$的信息增益比$g_{_R}(D,A)$定义为其信息增益$g(D,A)$与训练数据集$D$的经验熵$H(D)$之比：</p>
<script type="math/tex; mode=display">g_{_R}(D,A)=\frac{g(D,A)}{H(D)}</script></blockquote>
<p>$H(D)$表示数据集$D$因特征$A$的每一个取值而产生的总熵值，用信息增益除以$H(D)$就是信息增益比，该准则校正了信息增益偏向选择多值特征的问题，效果往往更好。</p>
<h3 id="基尼指数："><a href="#基尼指数：" class="headerlink" title="基尼指数："></a>基尼指数：</h3><blockquote>
<p><strong>定义5.4 （基尼指数）</strong> 分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为</p>
<script type="math/tex; mode=display">{\rm Gini}(p)=\sum_{k=1}^Kp_k(1-p_k)=1-\sum_{k=1}^Kp_k^2</script></blockquote>
<p>基尼指数则是定义了一个类似于熵的函数$Gini(p)$，该函数也可以用来描述数据集的不确定程度，对每一个特征，都可以计算出数据集在该特征条件下的基尼指数，于是选择使条件基尼指数最小的那个特征作为最优特征即可。</p>
<p><strong>注：上述准则的计算方法和应用在《统计学习方法》62页例5.2，71页例5.4都清楚的展示，这里不再赘述。</strong></p>
<h1 id="决策树生成的具体算法"><a href="#决策树生成的具体算法" class="headerlink" title="决策树生成的具体算法:"></a>决策树生成的具体算法:</h1><p>决策树学习的经典算法有ID3算法、C4.5算法、CART算法。</p>
<h2 id="ID3算法与C4-5算法："><a href="#ID3算法与C4-5算法：" class="headerlink" title="ID3算法与C4.5算法："></a>ID3算法与C4.5算法：</h2><p>如图为决策树学习的基本算法，从第8行起，选择最优划分属性的准则如果是信息增益准则，就是ID3算法，如果是信息增益比准则，那么就是C4.5算法了。因此这两种算法不再详细展开。<br><img src="/2018/03/24/统计学习方法第五章笔记/./决策树生成.jpg" alt="Alt text"></p>
<h2 id="CART算法："><a href="#CART算法：" class="headerlink" title="CART算法："></a>CART算法：</h2><p>CART算法全程为分类与回归树（Classification And Regression Tree），可见CART算法既可以用于分类，也可以用于回归。</p>
<p>与ID3和C4.5不同，CART假设决策树是二叉树，内部结点特征取值仅有两种可能——“是”或“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等于递归地二分每个特征。</p>
<h3 id="分类树："><a href="#分类树：" class="headerlink" title="分类树："></a>分类树：</h3><p>分类树用基尼指数选择最优特征，同时决定该特征的最优二值切分点。</p>
<p>具体方法是，选择特征A，对特征A的每一个取值$a_1、a_2 … a_n$，分别计算$Gini(D,A=a_1)$、$Gini(D,A=a_2) … Gini(D,A=a_n)$。再选择特征B，对特征B的每一个取$b_1、b_2 … b_n$，分别计算$Gini(D,B=b_1)、Gini(D,B=b_2) … Gini(D,B=b_n)$。再选择特征C….</p>
<p>将所有可能计算完毕后，比较它们的大小，假设$Gini(D,B=b_2)$最小，则选择特征$B$为最优特征，选择$b_2$为最优切分点（将$B=b_2$划分到左分支，$B≠b_2$划分到右分支）。完成一次划分后，对左右两分支继续上述计算，选择出后续的最优特征及最优切分点，直至满足停止条件。合适的停止条件的可以减小过拟合现象，一般来说，停止条件可以是没有更多特征用来分类，或结点中样本个数小于预定值，或样本集的基尼指数小于预定值等。</p>
<h3 id="回归树："><a href="#回归树：" class="headerlink" title="回归树："></a>回归树：</h3><p>CART树也可以用于回归任务，这时树的生成同样是递归地构建二叉决策树，只不过在回归任务中所使用的划分准则是平方误差最小化准则。</p>
<p>假设回归树已经生成，那么对于输入值$(x,y)$，回归树通过对$x$的每一个分量进行判断，并沿着一个路径到达树的底部单元$R_m$，那么输出值$C_m$就是在训练过程中所有被划分到$R_m$里的训练样本的$y$值的平均值。</p>
<p>于是在划分时就可以应用平方误差最小化准则，也就是在每一次划分后，实现在生成的两个分支中，分支$R_1$和$R_2$各自的样本与平均值所产生的总误差最小。如图所示：</p>
<script type="math/tex; mode=display">\min_{j,s}\left[\min_{c_1}\sum_{x_i \in R_1(j,s)}(y_i-c_1)^2+\min_{c_2} \sum_{x_i \in R_2(j,s)}(y_i-c_2)^2\right]</script><p>先固定要划分的变量，解出一个最优切分点$s$。然后遍历所有变量，找到最优切分变量$j$，构成一个对$(j,s)$。依次将输入空间划分为左右两个区域：</p>
<script type="math/tex; mode=display">R_1(j,s)=\{x\mid x^{(j)}\leqslant s\} \ and\ R_2(j,s)=\{x\mid x^{(j)}> s\}</script><p>在$R_1$和$R_2$上的取值分别为：</p>
<script type="math/tex; mode=display">\hat{c}_1=ave(y_i\mid x_i\in R_1(j,s))\ and\ \hat{c}_2=ave(y_i\mid x_i\in R_2(j,s))</script><p>然后对划分出来的两个区域重复上述过程，直到满足停止条件，这样就生成一颗回归树，称之为最小二乘回归树（least squares regression tree）。</p>
<script type="math/tex; mode=display">f(x)=\sum_{m=1}^{M}\hat{c}_mI(x\in R_m)</script><h1 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h1><p>决策树生成算法递归地对训练数据进行划分，直至进行不下去为止，这样生成的决策树对训练数据的分类很准确，但容易出现过拟合现象。究其原因，在于学习时分类太细，构建出过于复杂的决策树。解决这个问题的办法是对决策树进行简化，形象地称为剪枝操作。</p>
<h2 id="预剪枝："><a href="#预剪枝：" class="headerlink" title="预剪枝："></a>预剪枝：</h2><p>顾名思义，在决策树生成过程中，如果一次划分无法产生更有“价值”的子结点，也就是说不能带来决策树泛化性能的提升，那么就干脆不要进行这次划分，这就是预剪枝。<br><img src="/2018/03/24/统计学习方法第五章笔记/./预剪枝.jpg" alt="Alt text"><br>上图中验证集是通过对数据集采用留出法得到的。</p>
<h2 id="后剪枝："><a href="#后剪枝：" class="headerlink" title="后剪枝："></a>后剪枝：</h2><p>当决策树已经生成后，采用某些策略，从树上裁掉一些子树或叶结点，并将其父结点作为新的叶节点，从而简化树模型。</p>
<p>一种简单的剪枝算法是通过极小化决策树整体的损失函数或代价函数来实现。</p>
<blockquote>
<p><strong>算法5.4（树的剪枝算法）</strong><br>输入：生成算法产生的整个树$T$，参数$\alpha;$<br>输出：修剪后的子树$T_{\alpha}$<br>（1）计算每个结点的经验熵。<br>（2）递归地从树的叶节点向上回缩。</p>
</blockquote>
<p>其中$|T|$为树的叶节点个数，反应了模型的复杂程度。最小化整体损失函数就意味着预测误差和模型复杂度要同时都小才行。</p>
<p>具体的剪枝过程可以用动态规划的方法实现：</p>
<blockquote>
<p>设一组叶节点回缩到其父节点之前与之后的整体树分别为$T_B$与$T_A$，其对应的损失函数值分别是$C_{\alpha}(T_B)$与$C_{\alpha}(T_A)$，如果</p>
<script type="math/tex; mode=display">C_{\alpha}(T_A)\leqslant C_{\alpha}(T_B)</script><p>则进行剪枝，即将父节点变成新的叶节点。<br>（3）返回（2），直至不能继续为止，得到损失函数最小的子树$T_{\alpha}$<br>注意，上式只需要考虑两个树的损失函数的差，其计算可以在局部进行。所以，决策树的剪枝算法可以由一种动态规划的算法实现，类似的动态规划算法可以参见文献[10]。</p>
</blockquote>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/统计学习方法/" rel="tag"># 统计学习方法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/23/统计学习方法第四章笔记/" rel="next" title="《统计学习方法》第四章笔记">
                <i class="fa fa-chevron-left"></i> 《统计学习方法》第四章笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/25/统计学习方法第六章笔记/" rel="prev" title="《统计学习方法》第六章笔记">
                《统计学习方法》第六章笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/mountain.jpg"
                alt="neutronar" />
            
              <p class="site-author-name" itemprop="name">neutronar</p>
              <p class="site-description motion-element" itemprop="description">Another Mountain.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树"><span class="nav-number">1.</span> <span class="nav-text">决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树模型："><span class="nav-number">1.1.</span> <span class="nav-text">决策树模型：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树学习："><span class="nav-number">1.2.</span> <span class="nav-text">决策树学习：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#①如何把最优的决策树找出来呢？"><span class="nav-number">1.2.1.</span> <span class="nav-text">①如何把最优的决策树找出来呢？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#②什么样的特征是最优特征呢？如何定义划分的“有效”程度？"><span class="nav-number">1.2.2.</span> <span class="nav-text">②什么样的特征是最优特征呢？如何定义划分的“有效”程度？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征选择"><span class="nav-number">2.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#信息增益："><span class="nav-number">2.0.1.</span> <span class="nav-text">信息增益：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信息增益比："><span class="nav-number">2.0.2.</span> <span class="nav-text">信息增益比：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基尼指数："><span class="nav-number">2.0.3.</span> <span class="nav-text">基尼指数：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树生成的具体算法"><span class="nav-number">3.</span> <span class="nav-text">决策树生成的具体算法:</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ID3算法与C4-5算法："><span class="nav-number">3.1.</span> <span class="nav-text">ID3算法与C4.5算法：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CART算法："><span class="nav-number">3.2.</span> <span class="nav-text">CART算法：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#分类树："><span class="nav-number">3.2.1.</span> <span class="nav-text">分类树：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#回归树："><span class="nav-number">3.2.2.</span> <span class="nav-text">回归树：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树的剪枝"><span class="nav-number">4.</span> <span class="nav-text">决策树的剪枝</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#预剪枝："><span class="nav-number">4.1.</span> <span class="nav-text">预剪枝：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#后剪枝："><span class="nav-number">4.2.</span> <span class="nav-text">后剪枝：</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">neutronar</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
